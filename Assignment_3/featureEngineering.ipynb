{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.6.0.66)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy>=1.19.3 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images Data Augmentation\n",
    "## opencv important functions\n",
    "<b>get image size: </b>dimensions = img.shape </br>\n",
    "<b>image resizing: </b>new_img = cv2.resize(img, dim(new_width, new_height))</br>\n",
    "<b>transfer to grayscale</b>gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</br>\n",
    "\n",
    "## Examples for Data Augmentation\n",
    "### Affine transformation\n",
    "In geometry transformation is applied by a transofrmation matrix\n",
    "<ul>\n",
    "<li>For translation this matrix is used</li>\n",
    "<img src=\"images/5_translation.png\"></img>\n",
    "<li>For rotation this matrix is used</li>\n",
    "<img src=\"images/6_rotation.png\"></img>\n",
    "</ul>\n",
    "<b>opencv automates this process on the following two steps</b>\n",
    "<ol>\n",
    "<li>\n",
    "<b>Get transformation matrix</b>\n",
    "<ul>\n",
    "<li><b>For translation:</b> M = np.float32([[1,0,vertical_shift],[0,1,horizontal_shift]])</li>\n",
    "<li><b>For rotation:</b> M = cv::getRotationMatrix2D(center, rotation_angle, scale)</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>\n",
    "<b>apply transformation matrix on the image</b></br>\n",
    "transformed_img = cv2.warpAffine(img,M,(width,height))\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "### Image flipping\n",
    "flip_type = 0 #0: vertical, 1: horizontal, -1: bot vertical and horizontal\n",
    "flipped_img = cv2.flip(img, 0)\n",
    "\n",
    "### Adding Random Exposure (In case that the model should tolerate all lighting conditions)\n",
    "edit brightness and contrast\n",
    "transformed_img = cv2.convertScaleAbs(img, alph, beta)\n",
    "<ul> <li>alpha = 1.5 # Contrast control (1.0-3.0)</li>\n",
    "<li>beta = 0 # Brightness control (0-100)</li></ul>\n",
    "\n",
    "### Normalizing channels\n",
    "<ul>\n",
    "<li>Transform the color range from [0, 255] to [0, 1]</li>\n",
    "<li>Subtract the mean value of each channel</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opencv transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "img = cv2.imread('bird.jpg')\n",
    "\n",
    "#1_________ gray scale\n",
    "image = cv2.imread('bird.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Use the cvtColor() function to grayscale the image\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "cv2.imshow('Grayscale', gray_image)\n",
    "cv2.waitKey(0) \n",
    " \n",
    "# Window shown waits for any key pressing event\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create data augmentation function that exsposes 10 random examples of the input image\n",
    "image.shape\n",
    "#gray_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- resize\n",
    "r = 100.0 / image.shape[1]\n",
    "#dim = (128, int(image.shape[0] * r))\n",
    "dim = (128, 128)\n",
    "# perform the actual resizing of the image and show it\n",
    "resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"resized\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotation\n",
    "(h, w) = image.shape[:2]\n",
    "center = (w / 2, h / 2)\n",
    "# rotate the image by 180 degrees\n",
    "M = cv2.getRotationMatrix2D(center, 180, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h))\n",
    "cv2.imshow(\"rotated\", rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotation\n",
    "def rotation(image, angle):\n",
    "    angle = int(random.uniform(-angle, angle))\n",
    "    h, w = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    image = cv2.warpAffine(image, M, (w, h))\n",
    "    return image\n",
    "image = rotation(image, 30)    \n",
    "cv2.imshow('Result', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#scaling\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img = cv.imread('bird.jpg')\n",
    "res = cv.resize(img,None,fx=0.5, fy=2, interpolation = cv.INTER_CUBIC)\n",
    "#OR\n",
    "height, width = img.shape[:2]\n",
    "#res = cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_CUBIC)\n",
    "cv2.imshow('Result', res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translation\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img = cv.imread('bird.jpg',0)\n",
    "rows,cols = img.shape\n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "cv.imshow('img',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://github.com/random-forests/tensorflow-workshop/blob/master/archive/examples/07_structured_data.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "census_train = pd.read_csv('./data/census/train.csv', index_col=False) \n",
    "census_test = pd.read_csv('./data/census/test.csv', skiprows=1, index_col=False) \n",
    "\n",
    "\n",
    "census_train = census_train.dropna(how=\"any\", axis=0)\n",
    "census_test = census_test.dropna(how=\"any\", axis=0)\n",
    "\n",
    "#you turn! Analyise data\n",
    "# get hash unique values\n",
    "# get age unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the feature columns we'll use to train the Linear model\n",
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_253800/1387407375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#1- Numerical attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m##1.1- Bucketizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbucketized_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#1- Numerical attributes\n",
    "##1.1- Bucketizing\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.feature_column.bucketized_column\n",
    "\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "age_buckets_1 = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column('age'), \n",
    "    boundaries=[31, 46, 60, 75, 90] # specify the ranges\n",
    ")\n",
    "\n",
    "age_buckets_2 = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column('age'),\n",
    "    list(range(10))\n",
    ")\n",
    "\n",
    "feature_columns.append(age_buckets_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0, 1, 2]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth)  # output: [3 x 3]\n",
    "# [[1., 0., 0.],\n",
    "#  [0., 1., 0.],\n",
    "#  [0., 0., 1.]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "\n",
    "feature_columns.append(education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 hashed bucket\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native-country', 1000)\n",
    "feature_columns.append(native_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 cross column; combine two features\n",
    "age_cross_education = tf.feature_column.crossed_column(\n",
    "    [age_buckets_1, education],\n",
    "    hash_bucket_size=int(1e4) # Using a hash is handy here\n",
    ")\n",
    "feature_columns.append(age_cross_education)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d649404ee286c9341d586c87dba08392d8b7db27d1214df02d5d59f9ee48e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
